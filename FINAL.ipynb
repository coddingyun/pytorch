{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoTiZ9etqd7F+LgFySjGLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coddingyun/pytorch/blob/main/FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-UnPMgNlIEK"
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8oc3InHlLC2",
        "outputId": "a9503645-24ec-4011-d5be-b30d1f2da2f8"
      },
      "source": [
        "# Mnist 데이터셋 불러오기\n",
        "# mnist.load_data()로 한줄에 쉽게 데이터를 불러올 수 있다. # 다운로드 시간도 굉장히 빠르다\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXSqEmBGlMn8",
        "outputId": "cb0f0a32-0a72-4096-b390-4d9355500551"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqMrw1bZlO3k",
        "outputId": "619aed32-22fc-4a56-e4bb-e4c44dfe72c8"
      },
      "source": [
        "#Train set 과 Test set 정리하기\n",
        "#cnn model에 넣기 위해서는 배열의 형태, dimension을 맞춰 주어야 한다.\n",
        "input_shape = (28, 28, 1) # 샘플 수를 제외한 입력 형태를 정의, 모델에서 첫 레이어일 때만 정의, (행, 열, 채널 수)\n",
        "\n",
        "#input\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1) # 28 x28 사이즈, 채널 수 1: 흑백\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255. # 모든 값을 0과 1사이로 만들어 (scailing) 학습이 원활하도록 만든다\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "\n",
        "#label\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train) # one-hot 인코딩\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n",
            "Y_train shape: (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAFj2Ps9luA0",
        "outputId": "9fd205cd-0d8c-4b5d-e5cc-c72528b30644"
      },
      "source": [
        "#CNN 모델 만들기\n",
        "model = Sequential() #순차모델\n",
        "model.add(Conv2D(32, kernel_size=5, strides=1, padding='same',  #‘same’:출력 이미지 사이즈가 입력 이미지 사이즈와 동일\n",
        "                 activation='relu', # 활성화 함수\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "model.add(Conv2D(64, 2, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                200768    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 210,506\n",
            "Trainable params: 210,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szipFtcNKWvV"
      },
      "source": [
        "#Dropout\n",
        "\n",
        "![image.png](https://user-images.githubusercontent.com/22881216/65816695-1207ea80-e23a-11e9-923b-80f6dd564986.png)\n",
        "\n",
        "- 전체 weight를 계산에 참여시키는 것이 아니라 layer에 포함된 weight 중에서 일부만 참여시킨다.\n",
        "- 즉, 학습 시 뉴런을 임의로 삭제하여 학습하는 방법\n",
        "- 훈련 시에는 임의의 비율(dropout ratio) 만큼 뉴런을 삭제한다.\n",
        "\n",
        "\n",
        "### Dropout의 목표\n",
        "- 무작위로 dropout을 하면서 학습을 시키면 overfitting의 원인인 co-adaptation를 방지한다.\n",
        "  + co-adaptation 현상?\n",
        "    * 각각의 weight들이 서로 동조화 되는 현상\n",
        "    * 어느 unit이 잘못 학습한 것을 다른 unit이 보완해 줄 수 있는 형태로 학습하는 것.\n",
        "    * 각각의 unit이 독자적인 meaningful feature를 가지지 못하게 된다.\n",
        "- Dropout을 사용하면 각각의 unit이 meaningful feature를 가지도록 학습되므로 generalization error(일반화 오차)가 낮아지는 효과를 보인다.\n",
        "- 좀 더 선명한 feature(salient feature)를 얻을 수 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQJY_hFlnf3"
      },
      "source": [
        "#Flatten\n",
        "![image.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Flp8Uy%2FbtqA58bFVeS%2Fry5z3HTrNDwCEOfqgvPubk%2Fimg.png)\n",
        "\n",
        "- Convolution Layer나 Max Pooling Layer 를 반복적으로 거치면 주요 특징만 추출되고 추출된 주요 특징은 전결합층에 전달되어 학습된다. \n",
        "- 전결합층에 전달하기 위해 1차원 자료로 바꿔주는데 이때 사용되는 Layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_14oHT4ZlI04"
      },
      "source": [
        "#Dense\n",
        "![image.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbskuBH%2FbtqA4yIEQPD%2FkIv76pJK4PBkKpvUm7iPKk%2Fimg.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz4p3tjUlt60",
        "outputId": "a2fbe998-9799-4a80-c78d-e5353bccfc98"
      },
      "source": [
        "#CNN 모델 학습하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # softmax output layer # metrics는 평가기준, 일반적으로 accuracy\n",
        "hist = model.fit(X_train, Y_train,\n",
        "                 batch_size=128,\n",
        "                 epochs=20,\n",
        "                 verbose=1 # 얼마나 자세히 정보를 표기할 것인가\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 52s 110ms/step - loss: 0.3998 - accuracy: 0.8757\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 51s 109ms/step - loss: 0.1407 - accuracy: 0.9580\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 51s 109ms/step - loss: 0.1107 - accuracy: 0.9672\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 51s 109ms/step - loss: 0.0932 - accuracy: 0.9721\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0808 - accuracy: 0.9757\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 51s 109ms/step - loss: 0.0726 - accuracy: 0.9787\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 51s 109ms/step - loss: 0.0661 - accuracy: 0.9807\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0618 - accuracy: 0.9805\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0580 - accuracy: 0.9828\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0548 - accuracy: 0.9841\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0506 - accuracy: 0.9840\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0469 - accuracy: 0.9857\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0450 - accuracy: 0.9862\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0415 - accuracy: 0.9872\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0425 - accuracy: 0.9868\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0398 - accuracy: 0.9873\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0363 - accuracy: 0.9882\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0396 - accuracy: 0.9873\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0343 - accuracy: 0.9891\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 51s 108ms/step - loss: 0.0354 - accuracy: 0.9895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eeT-Ox_l5OW",
        "outputId": "85f4106f-0fae-480e-b32a-489b280ba6eb"
      },
      "source": [
        "# Test\n",
        "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
        "print('loss_and_metrics : ' + str(loss_and_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0227 - accuracy: 0.9931\n",
            "loss_and_metrics : [0.022723237052559853, 0.9930999875068665]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNG9csHV3P63"
      },
      "source": [
        "- keras 너무 간편하다!"
      ]
    }
  ]
}